### **ğŸ“Œ Workshop: Data Ingestion with dlt â€“ Homework Solutions**  

This workshop focused on **building scalable data ingestion pipelines** using **dlt** to extract NYC Taxi data from an API, load it into **DuckDB**, and run analytical queries.

---

## **ğŸš€ Solutions & Completed Tasks**  

### **1ï¸âƒ£ Installing & Checking dlt Version**  
```bash
!pip install dlt[duckdb]
!dlt --version
```
âœ… **Answer:** `dlt 1.6.1`  

---

### **2ï¸âƒ£ Extracting Data Using dlt & API Pagination**  

âœ… **Code for Extracting API Data**  
```python
@dlt.resource(name="rides")
def ny_taxi():
    client = RESTClient(
        base_url="https://us-central1-dlthub-analytics.cloudfunctions.net",
        paginator=PageNumberPaginator(
            base_page=1,
            total_path=None
        )
    )

    for page in client.paginate("data_engineering_zoomcamp_api"):  # API endpoint for retrieving taxi ride data
        yield page  # Yield data to manage memory
```
After connecting to the database and running the `DESCRIBE` function, the result shows **4 tables**.  

âœ… **Answer:** `4 tables`  

---

### **3ï¸âƒ£ Checking Total Number of Records**  
```python
len(df)
```
âœ… **Answer:** `10000 records`  

---

### **4ï¸âƒ£ Analyzing Trip Duration**  
Ran the provided SQL query to calculate the **average trip duration in minutes**.  
```python
with pipeline.sql_client() as client:
    res = client.execute_sql(
        """
        SELECT
        AVG(date_diff('minute', trip_pickup_date_time, trip_dropoff_date_time))
        FROM rides;
        """
    )
    print(res)
```
âœ… **Answer:** `12.3049 minutes`  

---

## **ğŸ›  Tools & Technologies Used**  
âœ… **dlt** â€“ Automating data ingestion  
âœ… **DuckDB** â€“ Storing & querying data locally  
âœ… **Python** â€“ Extracting, transforming, and analyzing data  
âœ… **SQL** â€“ Running analytical queries  
